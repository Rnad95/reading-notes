# Read: 44 -  Ethics

## Code of Ethics - [Link](https://www.acm.org/code-of-ethics)

---
The Code is designed to inspire and guide the ethical conduct of all computing professionals, including current and aspiring practitioners, instructors, students, influencer, and anyone who uses computing technology in an impactful way.

An essential aim of computing professionals is to minimize negative consequences of computing, including threats to health, safety, personal security, and privacy.

High quality professional work in computing depends on professional review at all stages.

As appropriate to the context and one's abilities, computing professionals should share technical knowledge with the public, foster awareness of computing, and encourage understanding of computing.

Additionally, a computing professional should respectfully address inaccurate or misleading information related to computing.

Consequently, computing professionals should not access another's computer system, software, or data without a reasonable belief that such an action would be authorized or a compelling belief that it is consistent with the public good.

Leaders should ensure that opportunities are available to computing professionals to help them improve their knowledge and skills in professionalism, in the practice of ethics, and in their technical specialties.

Computing professionals should be fully aware of the dangers of oversimplified approaches, the improbability of anticipating every possible operating condition, the inevitability of software errors, the interactions of systems and their contexts, and other issues related to the complexity of their profession—and thus be confident in taking on responsibilities for the work that they do.

Computing professionals should assist system users in monitoring the operational viability of their computing systems, and help them understand that timely replacement of inappropriate or outdated features or entire systems may be needed.

Computing professionals who recognize breaches of the Code should take actions to resolve the ethical issues they recognize, including, when reasonable, expressing their concern to the person or persons thought to be violating the Code.

## The Software Engineering Code of Ethics and Professional Practice - [Link](https://ethics.acm.org/code-of-ethics/software-engineering-code/)

---
Software Engineering Code of Ethics and Professional Practice (Version 5.2) as recommended by the ACM/IEEE-CS Joint Task Force on Software Engineering Ethics and Professional Practices and jointly approved by the ACM and the IEEE-CS as the standard for teaching and practicing software engineering.

Software engineers shall commit themselves to making the analysis, specification, design, development, testing and maintenance of software a beneficial and respected profession.

CLIENT AND EMPLOYER – Software engineers shall act in a manner that is in the best interests of their client and employer consistent with the public interest.

MANAGEMENT – Software engineering managers and leaders shall subscribe to and promote an ethical approach to the management of software development and maintenance.

To ensure, as much as possible, that their efforts will be used for good, software engineers must commit themselves to making software engineering a beneficial and respected profession.

These obligations are founded in the software engineer’s humanity, in special care owed to people affected by the work of software engineers, and the unique elements of the practice of software engineering.

These situations require the software engineer to use ethical judgment to act in a manner which is most consistent with the spirit of the Code of Ethics and Professional Practice, given the circumstances.

These Principles should influence software engineers to consider broadly who is affected by their work; to examine if they and their colleagues are treating other human beings with due respect; to consider how the public, if reasonably well informed, would view their decisions; to analyze how the least empowered will be affected by their decisions; and to consider whether their acts would be judged worthy of the ideal professional working as a software engineer.

However, even in this generality, the Code provides support for software engineers and managers of software engineers who need to take positive action in a specific case by documenting the ethical stance of the profession.

The Code helps to define those actions that are ethically improper to request of a software engineer or teams of software engineers.

As this Code expresses the consensus of the profession on ethical issues, it is a means to educate both the public and aspiring professionals about the ethical obligations of all software engineers.

Work to develop software and related documents that respect the privacy of those who will be affected by that software.

Software engineering managers and leaders shall subscribe to and promote an ethical approach to the management of software development and maintenance .

Ensure that there is a fair agreement concerning ownership of any software, processes, research, writing, or other intellectual property to which a software engineer has contributed.

Not unfairly intervene in the career of any colleague; however, concern for the employer, the client or public interest may compel software engineers, in good faith, to question the competence of a colleague.

## BIG DATA IS OUR GENERATION’S CIVIL RIGHTS ISSUE, AND WE DON’T KNOW IT - [Link](http://solveforinteresting.com/big-data-is-our-generations-civil-rights-issue-and-we-dont-know-it/)

---

Data doesn’t invade people’s lives. What’s really driving so-called Big Data isn’t the volume of information. It turns out Big Data doesn’t have to be all that big. Rather, it’s about a reconsideration of the fundamental economics of analyzing data.

![threeV](https://i.ibb.co/BrDyfyC/big-data-triangle.png)

I’d first heard this as the “three V’s of data”: Volume, Variety, and Velocity. Traditionally, getting two was easy but getting three was very, very, very expensive.

The advent of clouds, platforms like Hadoop, and the inexorable march of Moore’s Law means that now, analyzing data is trivially inexpensive. In the old, data-is-scarce model, companies had to decide what to collect first, and then collect it. A traditional enterprise data warehouse might have tracked sales of widgets by color, region, and size. This act of deciding what to store and how to store it is called designing the schema, and in many ways, it’s the moment where someone decides what the data is about.

That needs repeating:
You decide what data is about the moment you define its schema. With the new, data-is-abundant model, we collect first and ask questions later. The schema comes after the collection. This means we collect information long before we decide what it’s for.

>**MY OPINION**
I suppose that the big data is very important, the speed and the value and the huge mount of data source is increasing. But I think we need to manage the new database in some areas like extraction the data from many sources, changes to the logistics of data management with new database and integration approaches and so on. So, we don't need a big analytics project, we want a new data thinking to permeate our regular work.

##  Google Backtracks, Says Its AI Will Not Be Used for Weapons or Surveillance - [Link](https://gizmodo.com/in-reversal-google-says-its-ai-will-not-be-used-for-we-1826649327)

---

Google is committing to not using artificial intelligence for weapons or surveillance after employees protested the company’s involvement in Project Maven, a Pentagon pilot program that uses artificial intelligence to analyze drone footage. Google CEO Sundar Pichai announced the change in a set of AI principles released today.

The company would attempt to provide a “Google-earth-like” surveillance system, offering “an exquisite capability” for near real-time analysis of drone footage. Several employees said that they did not think the principles went far enough to hold Google accountable—for instance, Google’s AI guidelines include a nod to following “principles of international law” but do not explicitly commit to following international human rights law. 

“While Google’s statement rejects building AI systems for information gathering and surveillance that violates internationally accepted norms, we are concerned about this qualification,” said Peter Asaro, a professor at The New School and one of the authors of an open letter that calls on Google to cancel its Maven contract. 

“We will not be pursuing follow on contracts for the Maven project, and because of that, we are now working with our customer to responsibly fulfill our obligations in a way that works long-term for them and is also consistent with our AI principles,” she added, confirming Gizmodo’s reporting last week that Google would not seek to renew its Maven contract after it expires in 2019. 

“On most fronts, these are well thought-out principles, and with a few caveats we’d recommend that other major tech companies set out similar guidelines and objectives for their AI work,” Peter Eckersley, chief computer scientist at the Electronic Frontier Foundation, told Gizmodo. 

“The company has constrained itself to only assisting AI surveillance projects that don’t violate internationally accepted norms,” Eckersley said. 

“Ultimately, how the company enacts these principles is what will matter more than statements such as this,” Asaro said. 

One Googler told Gizmodo that the principles amounted to “a hollow PR statement.” “The international norms surrounding espionage, cyberoperations, mass information surveillance, and even drone surveillance are all contested and debated in the international sphere. “This contract involved drone video footage and low-res object identification using AI, saving lives was the overarching intent,” Greene wrote in a blog post.

>**OPINION:**
I am already thinking in my mind what the factors to say this topics is etremely good.  that there are many benefits of AI such as improved the accuracy and decision-making and predict about something like the market stock and weather and so on.
 Surely, no one want the war, but if the AI feild will be dangerous if it will use as arm in the wars
Recently, I see this aspect forming a single answer - we need to control this feild with many countries to ensure no one can use this in bad way.

## Microsoft AI Principles

---

**Responsible AI resources and tools**

Get access to tools, guidelines, and additional resources that will help you create a responsible AI solution.

**Research and collaboration for responsible AI:**
Microsoft is collaborating with researchers and academics around the globe in an effort to advance responsible AI practices and technologies. Visit our research collection to get an overview of this work.

**Establish a responsible AI strategy**
Learn how to develop your own responsible AI strategy and principles based on the values of your organization.

State Farm® and its affiliates are the largest providers of auto and home insurance in the U.S. To responsibly maintain and amplify its services, State Farm has established a governance system assigning accountability for AI and overseeing the development of AI solutions that benefit customers. Learn about State Farm and AI Learn about the dashboard Read about equity research Read about the Declaration Whitepaper Read the insurance whitepaper

## Ethical OS Toolkit

---
As technologists, it’s only natural that we spend most of our time focusing on how our tech will change the world for the better.
But perhaps it’s more useful, in some ways, to consider the glass half empty.
So until we get that crystal ball app, the best we can hope to do is anticipate the long-term social impact and unexpected uses of the tech we create today.
We’re thrilled to be working with Omidyar Network and the Institute for the Future on this initiative and to help our global network of more than 1,500 startups get ahead of problems before they happen.
NetCloak is a platform that democratizes data privacy, so we are applying the Ethical OS framework to shape not just our strategy and process but our core values as well.
But these issues are becoming more and more urgent to address.


## AI at Google: our principles

---

![Google](https://blog.google/static/blogv2/images/google-1000x1000.png)

At its heart, AI is computer programming that learns and adapts.
So today, we’re announcing seven principles to guide our work going forward.
As we consider potential development and uses of AI technologies, we will take into account a broad range of social and economic factors, and will proceed where we believe that the overall likely benefits substantially exceed the foreseeable risks and downsides.
And we will responsibly share AI knowledge by publishing educational materials, best practices, and research that enable more people to develop useful AI applications.
Technologies that gather or use information for surveillance violating internationally accepted norms.
As AI technologies progress, we’ll work with a range of stakeholders to promote thoughtful leadership in this area, drawing on scientifically rigorous and multidisciplinary approaches.